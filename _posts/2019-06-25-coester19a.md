---
abstract: We show that on every $n$-point HST metric, there is a randomized online
  algorithm for metrical task systems (MTS) that is $1$-competitive for service costs
  and $O(\log n)$-competitive for movement costs. In general, these refined guarantees
  are optimal up to the implicit constant. While an $O(\log n)$-competitive algorithm
  for MTS on HST metrics was developed by Bubeck et al. (2018), that approach could
  only establish an $O((\log n)^2)$-competitive ratio when the service costs are required
  to be $O(1)$-competitive. Our algorithm is an instantiation of online mirror descent
  with the regularizer derived from a multiscale conditional entropy. In fact, our
  algorithm satisfies a set of even more refined guarantees; we are able to exploit
  this property to combine it with known random embedding theorems and obtain, for
  {\em any} $n$-point metric space, a randomized algorithm that is $1$-competitive
  for service costs and $O((\log n)^2)$-competitive for movement costs.
section: contributed
title: Pure entropic regularization for metrical task systems
layout: inproceedings
series: Proceedings of Machine Learning Research
id: coester19a
month: 0
tex_title: Pure entropic regularization for metrical task systems
firstpage: 835
lastpage: 848
page: 835-848
order: 835
cycles: false
bibtex_author: Coester, Christian and Lee, James R.
author:
- given: Christian
  family: Coester
- given: James R.
  family: Lee
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/coester19a/coester19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
