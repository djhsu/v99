---
abstract: This joint extended abstract introduces and compares the results of (Auer
  et al., 2019) and (Chen et al., 2019), both of which resolve the problem of achieving
  optimal dynamic regret for non-stationary bandits without prior information on the
  non-stationarity. Specifically, Auer et al. (2019) resolve the problem for the traditional
  multi-armed bandits setting, while Chen et al. (2019) give a solution for the more
  general contextual bandits setting. Both works extend the key idea of (Auer et al.,
  2018) developed for a simpler two-armed setting.
section: contributed
title: Achieving Optimal Dynamic Regret for Non-stationary Bandits without Prior Information
layout: inproceedings
series: Proceedings of Machine Learning Research
id: auer19b
month: 0
tex_title: Achieving Optimal Dynamic Regret for Non-stationary Bandits without Prior
  Information
firstpage: 159
lastpage: 163
page: 159-163
order: 159
cycles: false
bibtex_author: Auer, Peter and Chen, Yifang and Gajane, Pratik and Lee, Chung-Wei
  and Luo, Haipeng and Ortner, Ronald and Wei, Chen-Yu
author:
- given: Peter
  family: Auer
- given: Yifang
  family: Chen
- given: Pratik
  family: Gajane
- given: Chung-Wei
  family: Lee
- given: Haipeng
  family: Luo
- given: Ronald
  family: Ortner
- given: Chen-Yu
  family: Wei
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/auer19b/auer19b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
