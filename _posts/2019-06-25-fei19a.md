---
abstract: We study the statistical performance of the semidefinite programming (SDP)
  relaxation approach for clustering under the binary symmetric Stochastic Block Model
  (SBM). We show that the SDP achieves an error rate of the form  $\exp\left[-(1-o(1))\frac{n
  I}{2}\right]$, where $I$ is an appropriate information-theoretic measure of the
  signal-to-noise ratio. This bound matches the minimax lower bound on the optimal
  Bayes error rate for this problem, and improves upon existing results that are sub-optimal
  by a multiplicative constant in the exponent. As a corollary, our result implies
  that SDP achieves the optimal exact recovery threshold with the correct leading
  constant. We further show that this error rate of SDP is robust; that is, it remains
  unchanged under the so-called semirandom model where the graph is modified by a
  monotone adversary, as well as under the setting with heterogeneous edge probabilities.
  Our proof is based on a novel primal-dual analysis of the SDP.
section: contributed
title: Achieving the Bayes Error Rate in Stochastic Block Model by SDP, Robustly
layout: inproceedings
series: Proceedings of Machine Learning Research
id: fei19a
month: 0
tex_title: Achieving the Bayes Error Rate in Stochastic Block Model by SDP, Robustly
firstpage: 1235
lastpage: 1269
page: 1235-1269
order: 1235
cycles: false
bibtex_author: Fei, Yingjie and Chen, Yudong
author:
- given: Yingjie
  family: Fei
- given: Yudong
  family: Chen
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/fei19a/fei19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
