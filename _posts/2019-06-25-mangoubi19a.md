---
abstract: The Langevin Markov chain algorithms are widely deployed methods to sample
  from distributions in challenging high-dimensional and non-convex statistics and
  machine learning applications. Despite this, current bounds for the Langevin algorithms
  are worse than those of competing algorithms in many important situations, for instance
  when sampling from weakly log-concave distributions, or when sampling or optimizing
  non-convex log-densities. We obtain improved bounds in many of these situations,
  showing that the Metropolis-adjusted Langevin algorithm (MALA) is faster than the
  best bounds for its competitor algorithms when the target distribution satisfies
  weak third- and fourth- order regularity properties associated with the input data.
  In many settings, our regularity conditions are weaker than the usual Euclidean
  operator norm regularity properties, allowing us to show faster bounds for a much
  larger class of distributions than would be possible with the usual Euclidean operator
  norm approach,  including in statistics and machine learning applications where
  the data satisfy a certain incoherence condition. In particular, we show that using
  our regularity conditions one can obtain faster bounds for applications which include
  sampling problems in Bayesian logistic regression with weakly convex priors, and
  the nonconvex optimization problem of learning linear classifiers with zero-one
  loss functions. Our main technical contribution is an analysis of the Metropolis
  acceptance probability of MALA in terms of its â€œenergy-conservation error," and
  a bound for this error in terms of third- and fourth- order regularity conditions.
  The combination of this higher-order analysis of the energy conservation error with
  the conductance method is key to obtaining bounds which have a sub-linear dependence
  on the dimension $d$ in the non-strongly logconcave setting.
section: contributed
title: Nonconvex sampling with the Metropolis-adjusted Langevin algorithm
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mangoubi19a
month: 0
tex_title: Nonconvex sampling with the Metropolis-adjusted Langevin algorithm
firstpage: 2259
lastpage: 2293
page: 2259-2293
order: 2259
cycles: false
bibtex_author: Mangoubi, Oren and Vishnoi, Nisheeth K
author:
- given: Oren
  family: Mangoubi
- given: Nisheeth K
  family: Vishnoi
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/mangoubi19a/mangoubi19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
