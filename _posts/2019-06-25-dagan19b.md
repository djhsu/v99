---
abstract: 'We show that fundamental learning tasks, such as  finding an approximate
  linear separator or linear regression, require memory at least  \emph{quadratic}
  in the dimension, in a natural streaming setting. This  implies that such problems
  cannot be solved (at least in this setting) by  scalable memory-efficient streaming
  algorithms. Our  results build  on a memory lower bound for a simple linear-algebraic
  problem  – finding approximate null vectors – and utilize the estimates on the packing
  of the Grassmannian, the manifold of all linear subspaces of fixed dimension. '
section: contributed
title: Space lower bounds for linear prediction in the streaming model
layout: inproceedings
series: Proceedings of Machine Learning Research
id: dagan19b
month: 0
tex_title: Space lower bounds for linear prediction in the streaming model
firstpage: 929
lastpage: 954
page: 929-954
order: 929
cycles: false
bibtex_author: Dagan, Yuval and Kur, Gil and Shamir, Ohad
author:
- given: Yuval
  family: Dagan
- given: Gil
  family: Kur
- given: Ohad
  family: Shamir
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/dagan19b/dagan19b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
