---
abstract: 'Existing depth separation results for constant-depth networks essentially
  show that certain radial functions in $\mathbb{R}^d$, which can be easily approximated
  with depth $3$ networks, cannot be approximated by depth $2$ networks, even up to
  constant accuracy, unless their size is exponential in $d$. However, the functions
  used to demonstrate this are rapidly oscillating, with a Lipschitz parameter scaling
  polynomially with the dimension $d$ (or equivalently, by scaling the function, the
  hardness result applies to $\mathcal{O}(1)$-Lipschitz functions only when the target
  accuracy $\epsilon$ is at most $\text{poly}(1/d)$). In this paper, we study whether
  such depth separations might still hold in the natural setting of $\mathcal{O}(1)$-Lipschitz
  radial functions, when $\epsilon$ does not scale with $d$. Perhaps surprisingly,
  we show that the answer is negative: In contrast to the intuition suggested by previous
  work, it \emph{is} possible to approximate $\mathcal{O}(1)$-Lipschitz radial functions
  with depth $2$, size $\text{poly}(d)$ networks, for every constant $\epsilon$. We
  complement it by showing that approximating such functions is also possible with
  depth $2$, size $\text{poly}(1/\epsilon)$ networks, for every constant $d$. Finally,
  we show that it is not possible to have polynomial dependence in both $d,1/\epsilon$
  simultaneously. Overall, our results indicate that in order to show depth separations
  for expressing $\mathcal{O}(1)$-Lipschitz functions with constant accuracy – if
  at all possible – one would need fundamentally different techniques than existing
  ones in the literature.'
section: contributed
title: 'Depth Separations in Neural Networks: What is Actually Being Separated?'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: safran19a
month: 0
tex_title: 'Depth Separations in Neural Networks: What is Actually Being Separated?'
firstpage: 2664
lastpage: 2666
page: 2664-2666
order: 2664
cycles: false
bibtex_author: Safran, Itay and Eldan, Ronen and Shamir, Ohad
author:
- given: Itay
  family: Safran
- given: Ronen
  family: Eldan
- given: Ohad
  family: Shamir
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/safran19a/safran19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
