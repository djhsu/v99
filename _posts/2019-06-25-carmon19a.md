---
abstract: We show that a simple randomized sketch of the matrix  multiplicative weight
  (MMW) update enjoys (in expectation) the same  regret bounds as MMW, up to a small
  constant factor. Unlike MMW, where  every step requires full matrix exponentiation,
  our steps require only a  single product of the form $e^A b$, which the Lanczos
  method  approximates efficiently. Our key technique is to view the sketch as a  \emph{randomized
  mirror projection}, and perform mirror descent analysis  on the \emph{expected projection}.
  Our sketch solves the online  eigenvector problem, improving the best known complexity
  bounds by  $\Omega(\log^5 n)$. We also apply this sketch to semidefinite  programming
  in saddle-point form, yielding a simple primal-dual scheme  with guarantees matching
  the best in the literature.
section: contributed
title: A Rank-1 Sketch for Matrix Multiplicative Weights
layout: inproceedings
series: Proceedings of Machine Learning Research
id: carmon19a
month: 0
tex_title: A Rank-1 Sketch for Matrix Multiplicative Weights
firstpage: 589
lastpage: 623
page: 589-623
order: 589
cycles: false
bibtex_author: Carmon, Yair and Duchi, John C and Aaron, Sidford and Kevin, Tian
author:
- given: Yair
  family: Carmon
- given: John C
  family: Duchi
- given: Sidford
  family: Aaron
- given: Tian
  family: Kevin
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/carmon19a/carmon19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
