---
abstract: " We present an approach that improves the sample complexity for a variety
  of curve fitting problems, including active learning for linear regression, polynomial
  regression, and continuous sparse Fourier transforms.  In the active linear regression
  problem, one would like to estimate the least squares solution $\\beta^*$ minimizing
  $\\|X\\beta - y\\|_2$ given the entire unlabeled dataset $X \\in \\mathbb{R}^{n
  \\times d}$ but only observing a small number of labels $y_i$.  We show that $O(d)$
  labels suffice to find a constant factor approximation $\\widetilde{\\beta}$: \\[
  \\mathbb{E}[\\|{X} \\widetilde{\\beta} - y \\|_2^2] \\leq 2 \\mathbb{E}[\\|X \\beta^*
  - y\\|_2^2]. \\]{This} improves on the best previous result of $O(d \\log d)$ from
  leverage score sampling.  We also present results for the \\emph{inductive} setting,
  showing when $\\widetilde{\\beta}$ will generalize to fresh samples; these apply
  to continuous settings such as polynomial regression.  Finally, we show how the
  techniques yield improved results for the non-linear sparse Fourier transform setting.
  \  "
section: contributed
title: Active Regression via Linear-Sample Sparsification
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chen19a
month: 0
tex_title: Active Regression via Linear-Sample Sparsification
firstpage: 663
lastpage: 695
page: 663-695
order: 663
cycles: false
bibtex_author: Chen, Xue and Price, Eric
author:
- given: Xue
  family: Chen
- given: Eric
  family: Price
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/chen19a/chen19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
