---
abstract: 'We study contextual bandit learning for any competitor policy class and
  continuous action space.  We obtain two qualitatively different regret bounds: one
  competes with a smoothed version of the policy class under no continuity assumptions,
  while the other requires standard Lipschitz assumptions. Both bounds exhibit data-dependent
  â€œzooming" behavior and, with no tuning, yield improved guarantees for benign problems.
  We also study adapting to unknown smoothness parameters, establishing a price-of-adaptivity
  and deriving optimal adaptive algorithms that require no additional information.'
section: contributed
title: 'Contextual bandits with continuous actions: Smoothing, zooming, and adapting'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: krishnamurthy19a
month: 0
tex_title: 'Contextual bandits with continuous actions: Smoothing, zooming, and adapting'
firstpage: 2025
lastpage: 2027
page: 2025-2027
order: 2025
cycles: false
bibtex_author: Krishnamurthy, Akshay and Langford, John and Slivkins, Aleksandrs and
  Zhang, Chicheng
author:
- given: Akshay
  family: Krishnamurthy
- given: John
  family: Langford
- given: Aleksandrs
  family: Slivkins
- given: Chicheng
  family: Zhang
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/krishnamurthy19a/krishnamurthy19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
