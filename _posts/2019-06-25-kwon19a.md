---
abstract: The Expectation-Maximization algorithm is perhaps the most broadly used
  algorithm for inference of latent variable problems. A theoretical understanding
  of its performance, however, largely remains lacking. Recent results established
  that EM enjoys global convergence for Gaussian Mixture Models. For Mixed Linear
  Regression, however, only local convergence results have been established, and those
  only for the high SNR regime. We show here that EM converges for mixed linear regression
  with two components (it is known that it may fail to converge for three or more),
  and moreover that this convergence holds for random initialization. Our analysis
  reveals that EM exhibits very different behavior in Mixed Linear Regression from
  its behavior in Gaussian Mixture Models, and hence our proofs require the development
  of several new ideas.
section: contributed
title: Global Convergence of the EM Algorithm for Mixtures of Two Component Linear
  Regression
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kwon19a
month: 0
tex_title: Global Convergence of the EM Algorithm for Mixtures of Two Component Linear
  Regression
firstpage: 2055
lastpage: 2110
page: 2055-2110
order: 2055
cycles: false
bibtex_author: Kwon, Jeongyeol and Qian, Wei and Caramanis, Constantine and Chen,
  Yudong and Davis, Damek
author:
- given: Jeongyeol
  family: Kwon
- given: Wei
  family: Qian
- given: Constantine
  family: Caramanis
- given: Yudong
  family: Chen
- given: Damek
  family: Davis
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/kwon19a/kwon19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
