---
abstract: We study the problem of recovering a hidden binary $k$-sparse $p$-dimensional
  vector $\beta$ from $n$ noisy linear observations $Y=X\beta+W$ where $X_{ij}$ are
  i.i.d.  $\mathcal{N}(0,1)$ and $W_i$ are i.i.d.  $\mathcal{N}(0,\sigma^2)$. A closely
  related  hypothesis testing problem is to distinguish the pair $(X,Y)$ generated
  from this structured model from a corresponding null model where $(X,Y)$ consist
  of purely independent Gaussian entries. In the low sparsity $k=o(p)$ and high signal
  to noise ratio $k/\sigma^2=\Omega\left(1\right)$ regime, we establish an “All-or-Nothing”
  information-theoretic phase transition at a critical sample size $n^*=2 k\log \left(p/k\right)
  /\log \left(1+k/\sigma^2\right)$, resolving a conjecture of [GamarnikZadik17]. Specifically,
  we show that if $\liminf_{p\rightarrow \infty} n/n^*>1$, then the maximum likelihood
  estimator almost perfectly recovers the hidden vector with high probability and
  moreover the true hypothesis can be detected with a vanishing error probability.
  Conversely, if $\limsup_{p\rightarrow \infty} n/n^*<1$, then it becomes information-theoretically
  impossible even to  recover an arbitrarily small but fixed fraction of the hidden
  vector support, or to test hypotheses strictly better than random guess. Our proof
  of the impossibility result builds upon two key techniques, which could be of independent
  interest. First, we use a conditional second moment method to upper bound the Kullback-Leibler
  (KL) divergence between the structured and the null model. Second, inspired by the
  celebrated area theorem, we establish a lower bound to the minimum mean squared
  estimation error of the hidden vector in terms of the KL divergence between the
  two models.
section: contributed
title: The All-or-Nothing Phenomenon in Sparse Linear Regression
layout: inproceedings
series: Proceedings of Machine Learning Research
id: reeves19a
month: 0
tex_title: The All-or-Nothing Phenomenon in Sparse Linear Regression
firstpage: 2652
lastpage: 2663
page: 2652-2663
order: 2652
cycles: false
bibtex_author: Reeves, Galen and Xu, Jiaming and Zadik, Ilias
author:
- given: Galen
  family: Reeves
- given: Jiaming
  family: Xu
- given: Ilias
  family: Zadik
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/reeves19a/reeves19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
